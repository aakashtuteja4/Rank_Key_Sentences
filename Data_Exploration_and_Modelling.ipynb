{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(sentence):\n",
    "    return Counter(word.lower().strip('.,') for word in sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"To Sherlock Holmes she is always the woman. I have\n",
    "seldom heard him mention her under any other name. In his eyes she\n",
    "eclipses and predominates the whole of her sex. It was not that he\n",
    "felt any emotion akin to love for Irene Adler. All emotions, and that\n",
    "one particularly, were abhorrent to his cold, precise but admirably\n",
    "balanced mind. He was, I take it, the most perfect reasoning and\n",
    "observing machine that the world has seen, but as a lover he would\n",
    "have placed himself in a false position. He never spoke of the softer\n",
    "passions, save with a gibe and a sneer. They were admirable things for\n",
    "the observer-excellent for drawing the veil from menâ€™s motives and\n",
    "actions. But for the trained reasoner to admit such intrusions into\n",
    "his own delicate and finely adjusted temperament was to introduce a\n",
    "distracting factor which might throw a doubt upon all his mental\n",
    "results. Grit in a sensitive instrument, or a crack in one of his own\n",
    "high-power lenses, would not be more disturbing than a strong emotion\n",
    "in a nature such as his. And yet there was but one woman to him, and\n",
    "that woman was the late Irene Adler, of dubious and questionable\n",
    "memory.\"\"\"\n",
    "\n",
    "document = ' '.join(document.strip().split('\\n'))\n",
    "sentence_tokenizer = PunktSentenceTokenizer()\n",
    "sentences = sentence_tokenizer.tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sen in sentences:\n",
    "#     print(bag_of_words(sen))\n",
    "\n",
    "\n",
    "c = CountVectorizer()\n",
    "bow_matrix = c.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.13737879, 0.04767903, 0.04305016,\n",
       "        0.04345599, 0.03330044, 0.05261648, 0.07798958, 0.        ,\n",
       "        0.20047419],\n",
       "       [0.        , 1.        , 0.0842143 , 0.07819597, 0.        ,\n",
       "        0.05171612, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05807146],\n",
       "       [0.13737879, 0.0842143 , 1.        , 0.        , 0.07004069,\n",
       "        0.09648614, 0.1069042 , 0.06701793, 0.09437203, 0.20474295,\n",
       "        0.1197599 ],\n",
       "       [0.04767903, 0.07819597, 0.        , 1.        , 0.07558987,\n",
       "        0.18678911, 0.05853972, 0.09249592, 0.10892262, 0.09110741,\n",
       "        0.24159019],\n",
       "       [0.04305016, 0.        , 0.07004069, 0.07558987, 1.        ,\n",
       "        0.07055583, 0.02370685, 0.07272032, 0.17253418, 0.08262451,\n",
       "        0.17789849],\n",
       "       [0.04345599, 0.05171612, 0.09648614, 0.18678911, 0.07055583,\n",
       "        1.        , 0.12952649, 0.06859301, 0.06837492, 0.13015945,\n",
       "        0.15423071],\n",
       "       [0.03330044, 0.        , 0.1069042 , 0.05853972, 0.02370685,\n",
       "        0.12952649, 1.        , 0.06307559, 0.03194234, 0.02852116,\n",
       "        0.11271501],\n",
       "       [0.05261648, 0.        , 0.06701793, 0.09249592, 0.07272032,\n",
       "        0.06859301, 0.06307559, 1.        , 0.09411725, 0.        ,\n",
       "        0.07702234],\n",
       "       [0.07798958, 0.        , 0.09437203, 0.10892262, 0.17253418,\n",
       "        0.06837492, 0.03194234, 0.09411725, 1.        , 0.12388421,\n",
       "        0.14327969],\n",
       "       [0.        , 0.        , 0.20474295, 0.09110741, 0.08262451,\n",
       "        0.13015945, 0.02852116, 0.        , 0.12388421, 1.        ,\n",
       "        0.04706138],\n",
       "       [0.20047419, 0.05807146, 0.1197599 , 0.24159019, 0.17789849,\n",
       "        0.15423071, 0.11271501, 0.07702234, 0.14327969, 0.04706138,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_matrix = TfidfTransformer().fit_transform(bow_matrix)\n",
    "similarity_graph = normalized_matrix * normalized_matrix.T\n",
    "similarity_graph.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.08385008597047344,\n",
       " 1: 0.07528144170324101,\n",
       " 2: 0.09838560290878208,\n",
       " 3: 0.09744270669005964,\n",
       " 4: 0.08926566466143131,\n",
       " 5: 0.09825615495072641,\n",
       " 6: 0.08261122644251108,\n",
       " 7: 0.08271845324598914,\n",
       " 8: 0.09433617163509285,\n",
       " 9: 0.08636822789376779,\n",
       " 10: 0.11148426389792515}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx_graph = nx.from_scipy_sparse_array(similarity_graph)\n",
    "scores = nx.pagerank(nx_graph)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
